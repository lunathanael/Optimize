{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lunathanael/Optimize/blob/main/optimize_gbt.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow_decision_forests\n",
        "# lib import\n",
        "import numpy as np\n",
        "from numpy import inf\n",
        "import pandas as pd\n",
        "import tensorflow_decision_forests as tfdf\n",
        "\n",
        "TRAINING = True"
      ],
      "metadata": {
        "papermill": {
          "duration": 13038.093127,
          "end_time": "2023-10-29T23:49:47.421754",
          "exception": false,
          "start_time": "2023-10-29T20:12:29.328627",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2023-11-04T06:45:02.852710Z",
          "iopub.execute_input": "2023-11-04T06:45:02.853037Z",
          "iopub.status.idle": "2023-11-04T06:45:03.368653Z",
          "shell.execute_reply.started": "2023-11-04T06:45:02.853010Z",
          "shell.execute_reply": "2023-11-04T06:45:03.367869Z"
        },
        "trusted": true,
        "id": "3gx6hloQreL5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_features(df):\n",
        "    features = ['seconds_in_bucket', 'imbalance_buy_sell_flag',\n",
        "               'imbalance_size', 'matched_size', 'bid_size', 'ask_size',\n",
        "                'reference_price','far_price', 'near_price', 'ask_price', 'bid_price', 'wap',\n",
        "                'imb_s1', 'imb_s2'\n",
        "               ]\n",
        "\n",
        "    df['imb_s1'] = df.eval('(bid_size-ask_size)/(bid_size+ask_size)')\n",
        "    df['imb_s2'] = df.eval('(imbalance_size-matched_size)/(matched_size+imbalance_size)')\n",
        "\n",
        "    prices = ['reference_price','far_price', 'near_price', 'ask_price', 'bid_price', 'wap']\n",
        "\n",
        "    for i,a in enumerate(prices):\n",
        "        for j,b in enumerate(prices):\n",
        "            if i>j:\n",
        "                df[f'{a}_{b}_imb'] = df.eval(f'({a}-{b})/({a}+{b})')\n",
        "                features.append(f'{a}_{b}_imb')\n",
        "\n",
        "    for i,a in enumerate(prices):\n",
        "        for j,b in enumerate(prices):\n",
        "            for k,c in enumerate(prices):\n",
        "                if i>j and j>k:\n",
        "                    max_ = df[[a,b,c]].max(axis=1)\n",
        "                    min_ = df[[a,b,c]].min(axis=1)\n",
        "                    mid_ = df[[a,b,c]].sum(axis=1)-min_-max_\n",
        "\n",
        "                    df[f'{a}_{b}_{c}_imb2'] = (max_-mid_)/(mid_-min_)\n",
        "                    features.append(f'{a}_{b}_{c}_imb2')\n",
        "\n",
        "    return df[features]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-04T06:45:03.369930Z",
          "iopub.execute_input": "2023-11-04T06:45:03.370305Z",
          "iopub.status.idle": "2023-11-04T06:45:03.381827Z",
          "shell.execute_reply.started": "2023-11-04T06:45:03.370271Z",
          "shell.execute_reply": "2023-11-04T06:45:03.380909Z"
        },
        "trusted": true,
        "id": "olcae27lreL6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if TRAINING:\n",
        "    # load dataset\n",
        "    df_train = pd.read_csv('./train.csv')\n",
        "    df_features = generate_features(df_train)\n",
        "\n",
        "    # data is defaulty normalized\n",
        "    X = np.float32(df_features.values)\n",
        "    Y = np.float32(df_train['target'].values)\n",
        "\n",
        "    X = X[np.isfinite(Y)]\n",
        "    Y = Y[np.isfinite(Y)]\n",
        "\n",
        "    index = np.arange(len(X)) #array for indexing\n",
        "\n",
        "    max_value = np.finfo(X.dtype).max #max float value allowed by numpy, perhaps lower? to prevent NAN during fit\n",
        "    min_value = np.finfo(X.dtype).min\n",
        "#     X[X==inf] = max_value\n",
        "#     X[~np.isfinite(X)] = min_value\n",
        "    X[X==inf] = 3.40282e+14\n",
        "    X[~np.isfinite(X)] = -3.40282e+14\n",
        "\n",
        "    del df_train\n",
        "    del df_features"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-04T06:45:50.497088Z",
          "iopub.execute_input": "2023-11-04T06:45:50.497478Z",
          "iopub.status.idle": "2023-11-04T06:47:39.343418Z",
          "shell.execute_reply.started": "2023-11-04T06:45:50.497447Z",
          "shell.execute_reply": "2023-11-04T06:47:39.341907Z"
        },
        "trusted": true,
        "id": "CRmFb8ZkreL7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "import os\n",
        "models = []\n",
        "\n",
        "# test to train ratio\n",
        "N_fold = 5\n",
        "\n",
        "#os.system('mkdir models')\n",
        "\n",
        "model_path ='/kaggle/input/testing_data_set'\n",
        "\n",
        "def train(model_dict, modelname='gbtm'):\n",
        "    if TRAINING:\n",
        "        model = model_dict[modelname]\n",
        "        model.fit(X[index%N_fold!=0], Y[index%N_fold!=0],\n",
        "          validation_data=(X[index%N_fold==0], Y[index%N_fold==0]),\n",
        "          verbose = 2\n",
        "         )\n",
        "        models.append(model)\n",
        "        joblib.dump(model, f'./models/{modelname}_{i}.model')\n",
        "    else:\n",
        "        models.append(joblib.load(f'{model_path}/{modelname}_{i}.model'))\n",
        "\n",
        "\n",
        "model_dict = {\n",
        "    'gbtm': tfdf.keras.GradientBoostedTreesModel(task = tfdf.keras.Task.REGRESSION,\n",
        "                                             split_axis='AXIS_ALIGNED',\n",
        "                                             categorical_algorithm='CART',\n",
        "                                             growing_strategy='LOCAL',\n",
        "                                             max_depth = 8,\n",
        "                                             sampling_method='RANDOM',\n",
        "                                             subsample=0.9,\n",
        "                                             shrinkage=0.1,\n",
        "                                             min_examples=10,\n",
        "                                             num_candidate_attributes_ratio=0.9,\n",
        "                                             early_stopping='LOSS_INCREASE',\n",
        "                                             early_stopping_initial_iteration=100,\n",
        "                                             random_seed = 69\n",
        "                                            ),\n",
        "}\n",
        "for i in range(N_fold):\n",
        "    train(model_dict, 'gbtm')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-04T06:47:43.792340Z",
          "iopub.execute_input": "2023-11-04T06:47:43.793097Z"
        },
        "trusted": true,
        "id": "SlEprcLnreL8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "bfc1a176-dbb9-4dba-c68f-cbcdf07dd683"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Use /tmp/tmplcgwh87_ as temporary training directory\n",
            "Reading training dataset...\n",
            "Training tensor examples:\n",
            "Features: Tensor(\"data:0\", shape=(None, 49), dtype=float32)\n",
            "Label: Tensor(\"data_1:0\", shape=(None,), dtype=float32)\n",
            "Weights: None\n",
            "Normalized tensor features:\n",
            " {'data:0.0': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice:0' shape=(None,) dtype=float32>), 'data:0.1': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_1:0' shape=(None,) dtype=float32>), 'data:0.2': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_2:0' shape=(None,) dtype=float32>), 'data:0.3': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_3:0' shape=(None,) dtype=float32>), 'data:0.4': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_4:0' shape=(None,) dtype=float32>), 'data:0.5': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_5:0' shape=(None,) dtype=float32>), 'data:0.6': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_6:0' shape=(None,) dtype=float32>), 'data:0.7': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_7:0' shape=(None,) dtype=float32>), 'data:0.8': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_8:0' shape=(None,) dtype=float32>), 'data:0.9': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_9:0' shape=(None,) dtype=float32>), 'data:0.10': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_10:0' shape=(None,) dtype=float32>), 'data:0.11': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_11:0' shape=(None,) dtype=float32>), 'data:0.12': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_12:0' shape=(None,) dtype=float32>), 'data:0.13': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_13:0' shape=(None,) dtype=float32>), 'data:0.14': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_14:0' shape=(None,) dtype=float32>), 'data:0.15': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_15:0' shape=(None,) dtype=float32>), 'data:0.16': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_16:0' shape=(None,) dtype=float32>), 'data:0.17': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_17:0' shape=(None,) dtype=float32>), 'data:0.18': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_18:0' shape=(None,) dtype=float32>), 'data:0.19': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_19:0' shape=(None,) dtype=float32>), 'data:0.20': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_20:0' shape=(None,) dtype=float32>), 'data:0.21': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_21:0' shape=(None,) dtype=float32>), 'data:0.22': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_22:0' shape=(None,) dtype=float32>), 'data:0.23': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_23:0' shape=(None,) dtype=float32>), 'data:0.24': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_24:0' shape=(None,) dtype=float32>), 'data:0.25': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_25:0' shape=(None,) dtype=float32>), 'data:0.26': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_26:0' shape=(None,) dtype=float32>), 'data:0.27': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_27:0' shape=(None,) dtype=float32>), 'data:0.28': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_28:0' shape=(None,) dtype=float32>), 'data:0.29': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_29:0' shape=(None,) dtype=float32>), 'data:0.30': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_30:0' shape=(None,) dtype=float32>), 'data:0.31': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_31:0' shape=(None,) dtype=float32>), 'data:0.32': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_32:0' shape=(None,) dtype=float32>), 'data:0.33': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_33:0' shape=(None,) dtype=float32>), 'data:0.34': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_34:0' shape=(None,) dtype=float32>), 'data:0.35': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_35:0' shape=(None,) dtype=float32>), 'data:0.36': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_36:0' shape=(None,) dtype=float32>), 'data:0.37': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_37:0' shape=(None,) dtype=float32>), 'data:0.38': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_38:0' shape=(None,) dtype=float32>), 'data:0.39': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_39:0' shape=(None,) dtype=float32>), 'data:0.40': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_40:0' shape=(None,) dtype=float32>), 'data:0.41': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_41:0' shape=(None,) dtype=float32>), 'data:0.42': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_42:0' shape=(None,) dtype=float32>), 'data:0.43': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_43:0' shape=(None,) dtype=float32>), 'data:0.44': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_44:0' shape=(None,) dtype=float32>), 'data:0.45': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_45:0' shape=(None,) dtype=float32>), 'data:0.46': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_46:0' shape=(None,) dtype=float32>), 'data:0.47': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_47:0' shape=(None,) dtype=float32>), 'data:0.48': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_48:0' shape=(None,) dtype=float32>)}\n",
            "Training dataset read in 0:10:04.977006. Found 4190313 examples.\n",
            "Reading validation dataset...\n",
            "Validation tensor examples:\n",
            "Features: Tensor(\"data:0\", shape=(None, 49), dtype=float32)\n",
            "Label: Tensor(\"data_1:0\", shape=(None,), dtype=float32)\n",
            "Weights: None\n",
            "Normalized tensor features:\n",
            " {'data:0.0': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice:0' shape=(None,) dtype=float32>), 'data:0.1': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_1:0' shape=(None,) dtype=float32>), 'data:0.2': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_2:0' shape=(None,) dtype=float32>), 'data:0.3': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_3:0' shape=(None,) dtype=float32>), 'data:0.4': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_4:0' shape=(None,) dtype=float32>), 'data:0.5': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_5:0' shape=(None,) dtype=float32>), 'data:0.6': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_6:0' shape=(None,) dtype=float32>), 'data:0.7': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_7:0' shape=(None,) dtype=float32>), 'data:0.8': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_8:0' shape=(None,) dtype=float32>), 'data:0.9': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_9:0' shape=(None,) dtype=float32>), 'data:0.10': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_10:0' shape=(None,) dtype=float32>), 'data:0.11': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_11:0' shape=(None,) dtype=float32>), 'data:0.12': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_12:0' shape=(None,) dtype=float32>), 'data:0.13': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_13:0' shape=(None,) dtype=float32>), 'data:0.14': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_14:0' shape=(None,) dtype=float32>), 'data:0.15': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_15:0' shape=(None,) dtype=float32>), 'data:0.16': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_16:0' shape=(None,) dtype=float32>), 'data:0.17': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_17:0' shape=(None,) dtype=float32>), 'data:0.18': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_18:0' shape=(None,) dtype=float32>), 'data:0.19': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_19:0' shape=(None,) dtype=float32>), 'data:0.20': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_20:0' shape=(None,) dtype=float32>), 'data:0.21': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_21:0' shape=(None,) dtype=float32>), 'data:0.22': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_22:0' shape=(None,) dtype=float32>), 'data:0.23': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_23:0' shape=(None,) dtype=float32>), 'data:0.24': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_24:0' shape=(None,) dtype=float32>), 'data:0.25': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_25:0' shape=(None,) dtype=float32>), 'data:0.26': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_26:0' shape=(None,) dtype=float32>), 'data:0.27': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_27:0' shape=(None,) dtype=float32>), 'data:0.28': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_28:0' shape=(None,) dtype=float32>), 'data:0.29': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_29:0' shape=(None,) dtype=float32>), 'data:0.30': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_30:0' shape=(None,) dtype=float32>), 'data:0.31': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_31:0' shape=(None,) dtype=float32>), 'data:0.32': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_32:0' shape=(None,) dtype=float32>), 'data:0.33': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_33:0' shape=(None,) dtype=float32>), 'data:0.34': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_34:0' shape=(None,) dtype=float32>), 'data:0.35': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_35:0' shape=(None,) dtype=float32>), 'data:0.36': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_36:0' shape=(None,) dtype=float32>), 'data:0.37': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_37:0' shape=(None,) dtype=float32>), 'data:0.38': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_38:0' shape=(None,) dtype=float32>), 'data:0.39': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_39:0' shape=(None,) dtype=float32>), 'data:0.40': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_40:0' shape=(None,) dtype=float32>), 'data:0.41': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_41:0' shape=(None,) dtype=float32>), 'data:0.42': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_42:0' shape=(None,) dtype=float32>), 'data:0.43': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_43:0' shape=(None,) dtype=float32>), 'data:0.44': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_44:0' shape=(None,) dtype=float32>), 'data:0.45': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_45:0' shape=(None,) dtype=float32>), 'data:0.46': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_46:0' shape=(None,) dtype=float32>), 'data:0.47': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_47:0' shape=(None,) dtype=float32>), 'data:0.48': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_48:0' shape=(None,) dtype=float32>)}\n",
            "Num validation examples: tf.Tensor(1047579, shape=(), dtype=int32)\n",
            "Validation dataset read in 0:02:33.682572. Found 1047579 examples.\n",
            "Training model...\n",
            "Standard output detected as not visible to the user e.g. running in a notebook. Creating a training log redirection. If training gets stuck, try calling tfdf.keras.set_training_logs_redirection(False).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[INFO 23-11-05 16:48:59.2254 UTC kernel.cc:773] Start Yggdrasil model training\n",
            "[INFO 23-11-05 16:48:59.2254 UTC kernel.cc:774] Collect training examples\n",
            "[INFO 23-11-05 16:48:59.2254 UTC kernel.cc:787] Dataspec guide:\n",
            "column_guides {\n",
            "  column_name_pattern: \"^__LABEL$\"\n",
            "  type: NUMERICAL\n",
            "}\n",
            "default_column_guide {\n",
            "  categorial {\n",
            "    max_vocab_count: 2000\n",
            "  }\n",
            "  discretized_numerical {\n",
            "    maximum_num_bins: 255\n",
            "  }\n",
            "}\n",
            "ignore_columns_without_guides: false\n",
            "detect_numerical_as_discretized_numerical: false\n",
            "\n",
            "[INFO 23-11-05 16:48:59.2267 UTC kernel.cc:393] Number of batches: 130948\n",
            "[INFO 23-11-05 16:48:59.2267 UTC kernel.cc:394] Number of examples: 4190313\n",
            "[INFO 23-11-05 16:49:00.2055 UTC kernel.cc:794] Training dataset:\n",
            "Number of records: 4190313\n",
            "Number of columns: 50\n",
            "\n",
            "Number of columns by type:\n",
            "\tNUMERICAL: 50 (100%)\n",
            "\n",
            "Columns:\n",
            "\n",
            "NUMERICAL: 50 (100%)\n",
            "\t0: \"__LABEL\" NUMERICAL mean:-0.0497912 min:-302.23 max:446.07 sd:9.38648\n",
            "\t1: \"data:0.0\" NUMERICAL mean:270.009 min:0 max:540 sd:158.745\n",
            "\t2: \"data:0.1\" NUMERICAL mean:-0.0135405 min:-1 max:1 sd:0.885101\n",
            "\t3: \"data:0.10\" NUMERICAL mean:-1.03133e+10 min:-3.40282e+14 max:1.07749 sd:1.87332e+12\n",
            "\t4: \"data:0.11\" NUMERICAL mean:-1.03133e+10 min:-3.40282e+14 max:1.07767 sd:1.87332e+12\n",
            "\t5: \"data:0.12\" NUMERICAL mean:-0.0137018 min:-0.999936 max:0.99994 sd:0.577446\n",
            "\t6: \"data:0.13\" NUMERICAL mean:-1.03133e+10 min:-3.40282e+14 max:0.983989 sd:1.87332e+12\n",
            "\t7: \"data:0.14\" NUMERICAL mean:-1.87996e+14 min:-3.40282e+14 max:0.995456 sd:1.69201e+14\n",
            "\t8: \"data:0.15\" NUMERICAL mean:-1.85613e+14 min:-3.40282e+14 max:0.131062 sd:1.69436e+14\n",
            "\t9: \"data:0.16\" NUMERICAL mean:-1.87996e+14 min:-3.40282e+14 max:0.999841 sd:1.69201e+14\n",
            "\t10: \"data:0.17\" NUMERICAL mean:-1.03133e+10 min:-3.40282e+14 max:0.0080918 sd:1.87332e+12\n",
            "\t11: \"data:0.18\" NUMERICAL mean:-1.87996e+14 min:-3.40282e+14 max:0.999845 sd:1.69201e+14\n",
            "\t12: \"data:0.19\" NUMERICAL mean:-1.85613e+14 min:-3.40282e+14 max:0.0540922 sd:1.69436e+14\n",
            "\t13: \"data:0.2\" NUMERICAL mean:-1.03076e+10 min:-3.40282e+14 max:2.98203e+09 sd:1.87332e+12\n",
            "\t14: \"data:0.20\" NUMERICAL mean:-1.03133e+10 min:-3.40282e+14 max:0.00473338 sd:1.87332e+12\n",
            "\t15: \"data:0.21\" NUMERICAL mean:-1.87996e+14 min:-3.40282e+14 max:0.999845 sd:1.69201e+14\n",
            "\t16: \"data:0.22\" NUMERICAL mean:-1.85613e+14 min:-3.40282e+14 max:0.0527488 sd:1.69436e+14\n",
            "\t17: \"data:0.23\" NUMERICAL mean:-1.03133e+10 min:-3.40282e+14 max:-1.49473e-06 sd:1.87332e+12\n",
            "\t18: \"data:0.24\" NUMERICAL mean:-1.03133e+10 min:-3.40282e+14 max:0.00672999 sd:1.87332e+12\n",
            "\t19: \"data:0.25\" NUMERICAL mean:-1.87996e+14 min:-3.40282e+14 max:0.999845 sd:1.69201e+14\n",
            "\t20: \"data:0.26\" NUMERICAL mean:-1.85613e+14 min:-3.40282e+14 max:0.0536176 sd:1.69436e+14\n",
            "\t21: \"data:0.27\" NUMERICAL mean:-1.03133e+10 min:-3.40282e+14 max:0 sd:1.87332e+12\n",
            "\t22: \"data:0.28\" NUMERICAL mean:-1.03133e+10 min:-3.40282e+14 max:0.0072404 sd:1.87332e+12\n",
            "\t23: \"data:0.29\" NUMERICAL mean:-1.46381e+13 min:-8.87497e+14 max:9.94665e+14 sd:8.47447e+13\n",
            "\t24: \"data:0.3\" NUMERICAL mean:-1.02683e+10 min:-3.40282e+14 max:7.71368e+09 sd:1.87332e+12\n",
            "\t25: \"data:0.30\" NUMERICAL mean:1.33744e+13 min:-4.62391e+16 max:2.26981e+17 sd:1.85864e+14\n",
            "\t26: \"data:0.31\" NUMERICAL mean:1.29783e+13 min:-8.97739e+14 max:8.99135e+14 sd:9.48561e+13\n",
            "\t27: \"data:0.32\" NUMERICAL mean:7.55216e+12 min:-8.87497e+14 max:9.57826e+14 sd:8.22656e+13\n",
            "\t28: \"data:0.33\" NUMERICAL mean:-4.45802e+12 min:-1.65395e+15 max:1.75739e+15 sd:4.36364e+13\n",
            "\t29: \"data:0.34\" NUMERICAL mean:-4.85338e+12 min:-8.99711e+14 max:8.96451e+14 sd:4.67298e+13\n",
            "\t30: \"data:0.35\" NUMERICAL mean:-2.64016e+12 min:-8.87497e+14 max:8.84534e+14 sd:5.23772e+13\n",
            "\t31: \"data:0.36\" NUMERICAL mean:2.89429e+13 min:-3.40282e+14 max:3.40282e+14 sd:9.49851e+13\n",
            "\t32: \"data:0.37\" NUMERICAL mean:4.40011e+12 min:-3.40282e+14 max:3.40282e+14 sd:3.85471e+13\n",
            "\t33: \"data:0.38\" NUMERICAL mean:5.13463e+12 min:-3.40282e+14 max:3.40282e+14 sd:4.15856e+13\n",
            "\t34: \"data:0.39\" NUMERICAL mean:7.06444e+12 min:-9.19698e+14 max:8.94694e+14 sd:4.89945e+13\n",
            "\t35: \"data:0.4\" NUMERICAL mean:51939.3 min:0.56 max:3.02878e+07 sd:111994\n",
            "\t36: \"data:0.40\" NUMERICAL mean:7.70641e+12 min:-4.51351e+14 max:4.46978e+14 sd:5.10678e+13\n",
            "\t37: \"data:0.41\" NUMERICAL mean:9.54366e+12 min:-8.80571e+14 max:8.882e+14 sd:5.78952e+13\n",
            "\t38: \"data:0.42\" NUMERICAL mean:1.96457e+11 min:-3.40282e+14 max:3.40282e+14 sd:1.19755e+13\n",
            "\t39: \"data:0.43\" NUMERICAL mean:5.73415e+10 min:-9.19698e+14 max:7.79717e+14 sd:6.2375e+12\n",
            "\t40: \"data:0.44\" NUMERICAL mean:5.93044e+10 min:-4.51351e+14 max:4.46037e+14 sd:6.12004e+12\n",
            "\t41: \"data:0.45\" NUMERICAL mean:2.90352e+13 min:-3.40282e+14 max:3.40282e+14 sd:9.5476e+13\n",
            "\t42: \"data:0.46\" NUMERICAL mean:4.38634e+12 min:-3.40282e+14 max:2.13807e+15 sd:3.8618e+13\n",
            "\t43: \"data:0.47\" NUMERICAL mean:5.12706e+12 min:-3.40282e+14 max:4.42262e+14 sd:4.16569e+13\n",
            "\t44: \"data:0.48\" NUMERICAL mean:2.04734e+11 min:-3.40282e+14 max:3.40282e+14 sd:8.75462e+12\n",
            "\t45: \"data:0.5\" NUMERICAL mean:53579.7 min:0.59 max:5.4405e+07 sd:129658\n",
            "\t46: \"data:0.6\" NUMERICAL mean:-1.03133e+10 min:-3.40282e+14 max:1.07749 sd:1.87332e+12\n",
            "\t47: \"data:0.7\" NUMERICAL mean:-1.87996e+14 min:-3.40282e+14 max:437.953 sd:1.69201e+14\n",
            "\t48: \"data:0.8\" NUMERICAL mean:-1.85613e+14 min:-3.40282e+14 max:1.30973 sd:1.69436e+14\n",
            "\t49: \"data:0.9\" NUMERICAL mean:-1.03133e+10 min:-3.40282e+14 max:1.07784 sd:1.87332e+12\n",
            "\n",
            "Terminology:\n",
            "\tnas: Number of non-available (i.e. missing) values.\n",
            "\tood: Out of dictionary.\n",
            "\tmanually-defined: Attribute which type is manually defined by the user i.e. the type was not automatically inferred.\n",
            "\ttokenized: The attribute value is obtained through tokenization.\n",
            "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
            "\tvocab-size: Number of unique values.\n",
            "\n",
            "[INFO 23-11-05 16:49:00.2060 UTC kernel.cc:799] Collect validation dataset\n",
            "[INFO 23-11-05 16:49:00.2061 UTC kernel.cc:393] Number of batches: 32737\n",
            "[INFO 23-11-05 16:49:00.2061 UTC kernel.cc:394] Number of examples: 1047579\n",
            "[INFO 23-11-05 16:49:00.4520 UTC kernel.cc:805] Validation dataset:\n",
            "Number of records: 1047579\n",
            "Number of columns: 50\n",
            "\n",
            "Number of columns by type:\n",
            "\tNUMERICAL: 50 (100%)\n",
            "\n",
            "Columns:\n",
            "\n",
            "NUMERICAL: 50 (100%)\n",
            "\t0: \"__LABEL\" NUMERICAL mean:-0.0386413 min:-385.29 max:357.44 sd:9.71382\n",
            "\t1: \"data:0.0\" NUMERICAL mean:269.967 min:0 max:540 sd:158.746\n",
            "\t2: \"data:0.1\" NUMERICAL mean:-0.00531893 min:-1 max:1 sd:0.886286\n",
            "\t3: \"data:0.10\" NUMERICAL mean:-1.62414e+09 min:-3.40282e+14 max:1.03284 sd:7.43412e+11\n",
            "\t4: \"data:0.11\" NUMERICAL mean:-1.62414e+09 min:-3.40282e+14 max:1.03426 sd:7.43412e+11\n",
            "\t5: \"data:0.12\" NUMERICAL mean:-0.0176723 min:-0.999896 max:0.999946 sd:0.587761\n",
            "\t6: \"data:0.13\" NUMERICAL mean:-1.62414e+09 min:-3.40282e+14 max:0.973598 sd:7.43412e+11\n",
            "\t7: \"data:0.14\" NUMERICAL mean:-1.88147e+14 min:-3.40282e+14 max:0.993494 sd:1.69185e+14\n",
            "\t8: \"data:0.15\" NUMERICAL mean:-1.85609e+14 min:-3.40282e+14 max:0.0479453 sd:1.69436e+14\n",
            "\t9: \"data:0.16\" NUMERICAL mean:-1.88147e+14 min:-3.40282e+14 max:0.999841 sd:1.69185e+14\n",
            "\t10: \"data:0.17\" NUMERICAL mean:-1.62414e+09 min:-3.40282e+14 max:0.00723934 sd:7.43412e+11\n",
            "\t11: \"data:0.18\" NUMERICAL mean:-1.88147e+14 min:-3.40282e+14 max:0.999845 sd:1.69185e+14\n",
            "\t12: \"data:0.19\" NUMERICAL mean:-1.85609e+14 min:-3.40282e+14 max:0.11032 sd:1.69436e+14\n",
            "\t13: \"data:0.2\" NUMERICAL mean:-1.6184e+09 min:-3.40282e+14 max:1.19269e+09 sd:7.43412e+11\n",
            "\t14: \"data:0.20\" NUMERICAL mean:-1.62414e+09 min:-3.40282e+14 max:0.00313479 sd:7.43412e+11\n",
            "\t15: \"data:0.21\" NUMERICAL mean:-1.88147e+14 min:-3.40282e+14 max:0.999845 sd:1.69185e+14\n",
            "\t16: \"data:0.22\" NUMERICAL mean:-1.85609e+14 min:-3.40282e+14 max:0.107143 sd:1.69436e+14\n",
            "\t17: \"data:0.23\" NUMERICAL mean:-1.62414e+09 min:-3.40282e+14 max:-2.00612e-06 sd:7.43412e+11\n",
            "\t18: \"data:0.24\" NUMERICAL mean:-1.62414e+09 min:-3.40282e+14 max:0.00537524 sd:7.43412e+11\n",
            "\t19: \"data:0.25\" NUMERICAL mean:-1.88147e+14 min:-3.40282e+14 max:0.999845 sd:1.69185e+14\n",
            "\t20: \"data:0.26\" NUMERICAL mean:-1.85609e+14 min:-3.40282e+14 max:0.109449 sd:1.69436e+14\n",
            "\t21: \"data:0.27\" NUMERICAL mean:-1.62414e+09 min:-3.40282e+14 max:0 sd:7.43412e+11\n",
            "\t22: \"data:0.28\" NUMERICAL mean:-1.62414e+09 min:-3.40282e+14 max:0.00645844 sd:7.43412e+11\n",
            "\t23: \"data:0.29\" NUMERICAL mean:-1.45718e+13 min:-1.00319e+15 max:8.80102e+14 sd:8.42881e+13\n",
            "\t24: \"data:0.3\" NUMERICAL mean:-1.57851e+09 min:-3.40282e+14 max:7.70462e+09 sd:7.43412e+11\n",
            "\t25: \"data:0.30\" NUMERICAL mean:1.35134e+13 min:-2.20187e+16 max:5.40527e+16 sd:1.25592e+14\n",
            "\t26: \"data:0.31\" NUMERICAL mean:1.28515e+13 min:-8.97946e+14 max:8.97937e+14 sd:9.32411e+13\n",
            "\t27: \"data:0.32\" NUMERICAL mean:8.03527e+12 min:-1.00319e+15 max:8.0927e+14 sd:8.16776e+13\n",
            "\t28: \"data:0.33\" NUMERICAL mean:-4.25817e+12 min:-9.04017e+14 max:1.13434e+15 sd:4.25992e+13\n",
            "\t29: \"data:0.34\" NUMERICAL mean:-4.59469e+12 min:-5.7202e+14 max:6.23956e+14 sd:4.57441e+13\n",
            "\t30: \"data:0.35\" NUMERICAL mean:-2.48502e+12 min:-8.86011e+14 max:8.80102e+14 sd:5.13811e+13\n",
            "\t31: \"data:0.36\" NUMERICAL mean:2.6616e+13 min:-3.40282e+14 max:3.40282e+14 sd:9.14103e+13\n",
            "\t32: \"data:0.37\" NUMERICAL mean:4.16601e+12 min:-3.40282e+14 max:3.40282e+14 sd:3.74256e+13\n",
            "\t33: \"data:0.38\" NUMERICAL mean:4.84808e+12 min:-3.40282e+14 max:3.40282e+14 sd:4.03619e+13\n",
            "\t34: \"data:0.39\" NUMERICAL mean:7.16024e+12 min:-4.5195e+14 max:4.49491e+14 sd:4.92836e+13\n",
            "\t35: \"data:0.4\" NUMERICAL mean:51315 min:12.71 max:2.70148e+07 sd:109105\n",
            "\t36: \"data:0.40\" NUMERICAL mean:7.76621e+12 min:-3.64305e+14 max:3.40282e+14 sd:5.12361e+13\n",
            "\t37: \"data:0.41\" NUMERICAL mean:9.54943e+12 min:-8.86263e+14 max:6.50824e+14 sd:5.79386e+13\n",
            "\t38: \"data:0.42\" NUMERICAL mean:2.21212e+11 min:-3.40282e+14 max:3.40282e+14 sd:1.18136e+13\n",
            "\t39: \"data:0.43\" NUMERICAL mean:6.87276e+10 min:-3.40282e+14 max:4.0395e+14 sd:5.83795e+12\n",
            "\t40: \"data:0.44\" NUMERICAL mean:6.72354e+10 min:-3.40282e+14 max:4.46068e+14 sd:5.75821e+12\n",
            "\t41: \"data:0.45\" NUMERICAL mean:2.6914e+13 min:-3.40282e+14 max:3.40282e+14 sd:9.22604e+13\n",
            "\t42: \"data:0.46\" NUMERICAL mean:4.19685e+12 min:-3.40282e+14 max:3.40282e+14 sd:3.77319e+13\n",
            "\t43: \"data:0.47\" NUMERICAL mean:4.93679e+12 min:-3.40282e+14 max:3.40282e+14 sd:4.08506e+13\n",
            "\t44: \"data:0.48\" NUMERICAL mean:1.97741e+11 min:-3.40282e+14 max:3.40282e+14 sd:8.26946e+12\n",
            "\t45: \"data:0.5\" NUMERICAL mean:53564.3 min:3.48 max:3.98234e+07 sd:128144\n",
            "\t46: \"data:0.6\" NUMERICAL mean:-1.62414e+09 min:-3.40282e+14 max:1.03854 sd:7.43412e+11\n",
            "\t47: \"data:0.7\" NUMERICAL mean:-1.88147e+14 min:-3.40282e+14 max:309.024 sd:1.69185e+14\n",
            "\t48: \"data:0.8\" NUMERICAL mean:-1.85609e+14 min:-3.40282e+14 max:1.12513 sd:1.69436e+14\n",
            "\t49: \"data:0.9\" NUMERICAL mean:-1.62414e+09 min:-3.40282e+14 max:1.03854 sd:7.43412e+11\n",
            "\n",
            "Terminology:\n",
            "\tnas: Number of non-available (i.e. missing) values.\n",
            "\tood: Out of dictionary.\n",
            "\tmanually-defined: Attribute which type is manually defined by the user i.e. the type was not automatically inferred.\n",
            "\ttokenized: The attribute value is obtained through tokenization.\n",
            "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
            "\tvocab-size: Number of unique values.\n",
            "\n",
            "[INFO 23-11-05 16:49:00.4521 UTC kernel.cc:810] Configure learner\n",
            "[WARNING 23-11-05 16:49:00.4522 UTC gradient_boosted_trees.cc:1830] \"goss_alpha\" set but \"sampling_method\" not equal to \"GOSS\".\n",
            "[WARNING 23-11-05 16:49:00.4522 UTC gradient_boosted_trees.cc:1841] \"goss_beta\" set but \"sampling_method\" not equal to \"GOSS\".\n",
            "[WARNING 23-11-05 16:49:00.4522 UTC gradient_boosted_trees.cc:1855] \"selective_gradient_boosting_ratio\" set but \"sampling_method\" not equal to \"SELGB\".\n",
            "[INFO 23-11-05 16:49:00.4523 UTC kernel.cc:824] Training config:\n",
            "learner: \"GRADIENT_BOOSTED_TREES\"\n",
            "features: \"^data:0\\\\.0$\"\n",
            "features: \"^data:0\\\\.1$\"\n",
            "features: \"^data:0\\\\.10$\"\n",
            "features: \"^data:0\\\\.11$\"\n",
            "features: \"^data:0\\\\.12$\"\n",
            "features: \"^data:0\\\\.13$\"\n",
            "features: \"^data:0\\\\.14$\"\n",
            "features: \"^data:0\\\\.15$\"\n",
            "features: \"^data:0\\\\.16$\"\n",
            "features: \"^data:0\\\\.17$\"\n",
            "features: \"^data:0\\\\.18$\"\n",
            "features: \"^data:0\\\\.19$\"\n",
            "features: \"^data:0\\\\.2$\"\n",
            "features: \"^data:0\\\\.20$\"\n",
            "features: \"^data:0\\\\.21$\"\n",
            "features: \"^data:0\\\\.22$\"\n",
            "features: \"^data:0\\\\.23$\"\n",
            "features: \"^data:0\\\\.24$\"\n",
            "features: \"^data:0\\\\.25$\"\n",
            "features: \"^data:0\\\\.26$\"\n",
            "features: \"^data:0\\\\.27$\"\n",
            "features: \"^data:0\\\\.28$\"\n",
            "features: \"^data:0\\\\.29$\"\n",
            "features: \"^data:0\\\\.3$\"\n",
            "features: \"^data:0\\\\.30$\"\n",
            "features: \"^data:0\\\\.31$\"\n",
            "features: \"^data:0\\\\.32$\"\n",
            "features: \"^data:0\\\\.33$\"\n",
            "features: \"^data:0\\\\.34$\"\n",
            "features: \"^data:0\\\\.35$\"\n",
            "features: \"^data:0\\\\.36$\"\n",
            "features: \"^data:0\\\\.37$\"\n",
            "features: \"^data:0\\\\.38$\"\n",
            "features: \"^data:0\\\\.39$\"\n",
            "features: \"^data:0\\\\.4$\"\n",
            "features: \"^data:0\\\\.40$\"\n",
            "features: \"^data:0\\\\.41$\"\n",
            "features: \"^data:0\\\\.42$\"\n",
            "features: \"^data:0\\\\.43$\"\n",
            "features: \"^data:0\\\\.44$\"\n",
            "features: \"^data:0\\\\.45$\"\n",
            "features: \"^data:0\\\\.46$\"\n",
            "features: \"^data:0\\\\.47$\"\n",
            "features: \"^data:0\\\\.48$\"\n",
            "features: \"^data:0\\\\.5$\"\n",
            "features: \"^data:0\\\\.6$\"\n",
            "features: \"^data:0\\\\.7$\"\n",
            "features: \"^data:0\\\\.8$\"\n",
            "features: \"^data:0\\\\.9$\"\n",
            "label: \"^__LABEL$\"\n",
            "task: REGRESSION\n",
            "random_seed: 69\n",
            "metadata {\n",
            "  framework: \"TF Keras\"\n",
            "}\n",
            "pure_serving_model: false\n",
            "[yggdrasil_decision_forests.model.gradient_boosted_trees.proto.gradient_boosted_trees_config] {\n",
            "  num_trees: 300\n",
            "  decision_tree {\n",
            "    max_depth: 8\n",
            "    min_examples: 10\n",
            "    in_split_min_examples_check: true\n",
            "    keep_non_leaf_label_distribution: true\n",
            "    missing_value_policy: GLOBAL_IMPUTATION\n",
            "    allow_na_conditions: false\n",
            "    categorical_set_greedy_forward {\n",
            "      sampling: 0.1\n",
            "      max_num_items: -1\n",
            "      min_item_frequency: 1\n",
            "    }\n",
            "    growing_strategy_local {\n",
            "    }\n",
            "    categorical {\n",
            "      cart {\n",
            "      }\n",
            "    }\n",
            "    num_candidate_attributes_ratio: 0.9\n",
            "    axis_aligned_split {\n",
            "    }\n",
            "    internal {\n",
            "      sorting_strategy: PRESORTED\n",
            "    }\n",
            "    uplift {\n",
            "      min_examples_in_treatment: 5\n",
            "      split_score: KULLBACK_LEIBLER\n",
            "    }\n",
            "  }\n",
            "  shrinkage: 0.1\n",
            "  loss: DEFAULT\n",
            "  validation_set_ratio: 0.1\n",
            "  validation_interval_in_trees: 1\n",
            "  early_stopping: VALIDATION_LOSS_INCREASE\n",
            "  early_stopping_num_trees_look_ahead: 30\n",
            "  l2_regularization: 0\n",
            "  lambda_loss: 1\n",
            "  mart {\n",
            "  }\n",
            "  adapt_subsample_for_maximum_training_duration: false\n",
            "  l1_regularization: 0\n",
            "  use_hessian_gain: false\n",
            "  l2_regularization_categorical: 1\n",
            "  stochastic_gradient_boosting {\n",
            "    ratio: 0.9\n",
            "  }\n",
            "  apply_link_function: true\n",
            "  compute_permutation_variable_importance: false\n",
            "  binary_focal_loss_options {\n",
            "    misprediction_exponent: 2\n",
            "    positive_sample_coefficient: 0.5\n",
            "  }\n",
            "  early_stopping_initial_iteration: 100\n",
            "}\n",
            "\n",
            "[INFO 23-11-05 16:49:00.4532 UTC kernel.cc:827] Deployment config:\n",
            "cache_path: \"/tmp/tmplcgwh87_/working_cache\"\n",
            "num_threads: 12\n",
            "try_resume_training: true\n",
            "\n",
            "[INFO 23-11-05 16:49:00.5109 UTC kernel.cc:889] Train model\n",
            "[INFO 23-11-05 16:49:00.5112 UTC gradient_boosted_trees.cc:470] Default loss set to SQUARED_ERROR\n",
            "[INFO 23-11-05 16:49:00.5112 UTC gradient_boosted_trees.cc:1097] Training gradient boosted tree on 4190313 example(s) and 49 feature(s).\n",
            "[INFO 23-11-05 16:49:00.5116 UTC gradient_boosted_trees.cc:1140] 4190313 examples used for training and 1047579 examples used for validation\n",
            "[INFO 23-11-05 16:49:12.4074 UTC gradient_boosted_trees.cc:1554] \tnum-trees:1 train-loss:9.360278 train-rmse:9.360278 valid-loss:9.685896 valid-rmse:9.685896\n",
            "[INFO 23-11-05 16:49:21.8745 UTC gradient_boosted_trees.cc:1556] \tnum-trees:2 train-loss:9.338104 train-rmse:9.338104 valid-loss:9.661929 valid-rmse:9.661929\n",
            "[INFO 23-11-05 16:50:00.0385 UTC gradient_boosted_trees.cc:1556] \tnum-trees:6 train-loss:9.279828 train-rmse:9.279828 valid-loss:9.603826 valid-rmse:9.603826\n",
            "[INFO 23-11-05 16:50:37.9932 UTC gradient_boosted_trees.cc:1556] \tnum-trees:10 train-loss:9.246928 train-rmse:9.246928 valid-loss:9.575972 valid-rmse:9.575972\n",
            "[INFO 23-11-05 16:51:15.2709 UTC gradient_boosted_trees.cc:1556] \tnum-trees:14 train-loss:9.226628 train-rmse:9.226628 valid-loss:9.562247 valid-rmse:9.562247\n",
            "[INFO 23-11-05 16:51:52.6149 UTC gradient_boosted_trees.cc:1556] \tnum-trees:18 train-loss:9.212502 train-rmse:9.212502 valid-loss:9.557096 valid-rmse:9.557096\n",
            "[INFO 23-11-05 16:52:29.8256 UTC gradient_boosted_trees.cc:1556] \tnum-trees:22 train-loss:9.201610 train-rmse:9.201610 valid-loss:9.555516 valid-rmse:9.555516\n",
            "[INFO 23-11-05 16:53:07.1691 UTC gradient_boosted_trees.cc:1556] \tnum-trees:26 train-loss:9.194274 train-rmse:9.194274 valid-loss:9.553017 valid-rmse:9.553017\n",
            "[INFO 23-11-05 16:53:45.2853 UTC gradient_boosted_trees.cc:1556] \tnum-trees:30 train-loss:9.187627 train-rmse:9.187627 valid-loss:9.551191 valid-rmse:9.551191\n",
            "[INFO 23-11-05 16:54:23.1118 UTC gradient_boosted_trees.cc:1556] \tnum-trees:34 train-loss:9.180776 train-rmse:9.180776 valid-loss:9.547138 valid-rmse:9.547138\n",
            "[INFO 23-11-05 16:55:00.3557 UTC gradient_boosted_trees.cc:1556] \tnum-trees:38 train-loss:9.169629 train-rmse:9.169629 valid-loss:9.545753 valid-rmse:9.545753\n",
            "[INFO 23-11-05 16:55:37.7402 UTC gradient_boosted_trees.cc:1556] \tnum-trees:42 train-loss:9.161391 train-rmse:9.161391 valid-loss:9.543216 valid-rmse:9.543216\n",
            "[INFO 23-11-05 16:56:15.3762 UTC gradient_boosted_trees.cc:1556] \tnum-trees:46 train-loss:9.155457 train-rmse:9.155457 valid-loss:9.541266 valid-rmse:9.541266\n",
            "[INFO 23-11-05 16:56:52.8125 UTC gradient_boosted_trees.cc:1556] \tnum-trees:50 train-loss:9.149496 train-rmse:9.149496 valid-loss:9.539886 valid-rmse:9.539886\n",
            "[INFO 23-11-05 16:57:30.3393 UTC gradient_boosted_trees.cc:1556] \tnum-trees:54 train-loss:9.145868 train-rmse:9.145868 valid-loss:9.542242 valid-rmse:9.542242\n",
            "[INFO 23-11-05 16:58:07.4321 UTC gradient_boosted_trees.cc:1556] \tnum-trees:58 train-loss:9.142323 train-rmse:9.142323 valid-loss:9.543082 valid-rmse:9.543082\n",
            "[INFO 23-11-05 16:58:44.3500 UTC gradient_boosted_trees.cc:1556] \tnum-trees:62 train-loss:9.138094 train-rmse:9.138094 valid-loss:9.543758 valid-rmse:9.543758\n",
            "[INFO 23-11-05 16:59:20.1352 UTC gradient_boosted_trees.cc:1556] \tnum-trees:66 train-loss:9.130886 train-rmse:9.130886 valid-loss:9.541431 valid-rmse:9.541431\n",
            "[INFO 23-11-05 16:59:55.9678 UTC gradient_boosted_trees.cc:1556] \tnum-trees:70 train-loss:9.127948 train-rmse:9.127948 valid-loss:9.541883 valid-rmse:9.541883\n",
            "[INFO 23-11-05 17:00:31.4435 UTC gradient_boosted_trees.cc:1556] \tnum-trees:74 train-loss:9.122645 train-rmse:9.122645 valid-loss:9.539929 valid-rmse:9.539929\n",
            "[INFO 23-11-05 17:01:06.8685 UTC gradient_boosted_trees.cc:1556] \tnum-trees:78 train-loss:9.118545 train-rmse:9.118545 valid-loss:9.539873 valid-rmse:9.539873\n",
            "[INFO 23-11-05 17:01:42.8118 UTC gradient_boosted_trees.cc:1556] \tnum-trees:82 train-loss:9.115248 train-rmse:9.115248 valid-loss:9.537282 valid-rmse:9.537282\n",
            "[INFO 23-11-05 17:02:18.3990 UTC gradient_boosted_trees.cc:1556] \tnum-trees:86 train-loss:9.112411 train-rmse:9.112411 valid-loss:9.536016 valid-rmse:9.536016\n",
            "[INFO 23-11-05 17:02:54.3015 UTC gradient_boosted_trees.cc:1556] \tnum-trees:90 train-loss:9.108418 train-rmse:9.108418 valid-loss:9.536362 valid-rmse:9.536362\n",
            "[INFO 23-11-05 17:03:30.0519 UTC gradient_boosted_trees.cc:1556] \tnum-trees:94 train-loss:9.105584 train-rmse:9.105584 valid-loss:9.537931 valid-rmse:9.537931\n",
            "[INFO 23-11-05 17:04:05.7732 UTC gradient_boosted_trees.cc:1556] \tnum-trees:98 train-loss:9.104234 train-rmse:9.104234 valid-loss:9.537895 valid-rmse:9.537895\n",
            "[INFO 23-11-05 17:04:40.9698 UTC gradient_boosted_trees.cc:1556] \tnum-trees:102 train-loss:9.100021 train-rmse:9.100021 valid-loss:9.537695 valid-rmse:9.537695\n",
            "[INFO 23-11-05 17:05:16.6461 UTC gradient_boosted_trees.cc:1556] \tnum-trees:106 train-loss:9.096850 train-rmse:9.096850 valid-loss:9.536712 valid-rmse:9.536712\n",
            "[INFO 23-11-05 17:05:52.3515 UTC gradient_boosted_trees.cc:1556] \tnum-trees:110 train-loss:9.093401 train-rmse:9.093401 valid-loss:9.537052 valid-rmse:9.537052\n",
            "[INFO 23-11-05 17:06:28.0940 UTC gradient_boosted_trees.cc:1556] \tnum-trees:114 train-loss:9.090377 train-rmse:9.090377 valid-loss:9.537469 valid-rmse:9.537469\n",
            "[INFO 23-11-05 17:07:03.9650 UTC gradient_boosted_trees.cc:1556] \tnum-trees:118 train-loss:9.087607 train-rmse:9.087607 valid-loss:9.538694 valid-rmse:9.538694\n",
            "[INFO 23-11-05 17:07:38.7549 UTC gradient_boosted_trees.cc:1556] \tnum-trees:122 train-loss:9.083031 train-rmse:9.083031 valid-loss:9.538501 valid-rmse:9.538501\n",
            "[INFO 23-11-05 17:08:14.7374 UTC gradient_boosted_trees.cc:1556] \tnum-trees:126 train-loss:9.080253 train-rmse:9.080253 valid-loss:9.538707 valid-rmse:9.538707\n",
            "[INFO 23-11-05 17:08:50.1594 UTC gradient_boosted_trees.cc:1556] \tnum-trees:130 train-loss:9.077271 train-rmse:9.077271 valid-loss:9.537598 valid-rmse:9.537598\n",
            "[INFO 23-11-05 17:09:25.6506 UTC gradient_boosted_trees.cc:1556] \tnum-trees:134 train-loss:9.074763 train-rmse:9.074763 valid-loss:9.537541 valid-rmse:9.537541\n",
            "[INFO 23-11-05 17:10:01.0985 UTC gradient_boosted_trees.cc:1556] \tnum-trees:138 train-loss:9.071971 train-rmse:9.071971 valid-loss:9.537189 valid-rmse:9.537189\n",
            "[INFO 23-11-05 17:10:36.7686 UTC gradient_boosted_trees.cc:1556] \tnum-trees:142 train-loss:9.070227 train-rmse:9.070227 valid-loss:9.537237 valid-rmse:9.537237\n",
            "[INFO 23-11-05 17:11:12.5230 UTC gradient_boosted_trees.cc:1556] \tnum-trees:146 train-loss:9.066971 train-rmse:9.066971 valid-loss:9.538126 valid-rmse:9.538126\n",
            "[INFO 23-11-05 17:11:48.1928 UTC gradient_boosted_trees.cc:1556] \tnum-trees:150 train-loss:9.064349 train-rmse:9.064349 valid-loss:9.537897 valid-rmse:9.537897\n",
            "[INFO 23-11-05 17:12:24.0288 UTC gradient_boosted_trees.cc:1556] \tnum-trees:154 train-loss:9.062517 train-rmse:9.062517 valid-loss:9.539618 valid-rmse:9.539618\n",
            "[INFO 23-11-05 17:12:59.5516 UTC gradient_boosted_trees.cc:1556] \tnum-trees:158 train-loss:9.059930 train-rmse:9.059930 valid-loss:9.538697 valid-rmse:9.538697\n",
            "[INFO 23-11-05 17:13:35.1680 UTC gradient_boosted_trees.cc:1556] \tnum-trees:162 train-loss:9.057558 train-rmse:9.057558 valid-loss:9.538282 valid-rmse:9.538282\n",
            "[INFO 23-11-05 17:14:10.5026 UTC early_stopping.cc:53] Early stop of the training because the validation loss does not decrease anymore. Best valid-loss: 9.5365\n",
            "[INFO 23-11-05 17:14:10.5027 UTC gradient_boosted_trees.cc:1606] Create final snapshot of the model at iteration 165\n",
            "[INFO 23-11-05 17:14:10.5186 UTC gradient_boosted_trees.cc:249] Truncates the model to 136 tree(s) i.e. 136  iteration(s).\n",
            "[INFO 23-11-05 17:14:10.5189 UTC gradient_boosted_trees.cc:312] Final model num-trees:136 valid-loss:9.536504 valid-rmse:9.536504\n",
            "[INFO 23-11-05 17:14:10.5280 UTC kernel.cc:926] Export model in log directory: /tmp/tmplcgwh87_ with prefix f76f0a1b20c74e3a\n",
            "[INFO 23-11-05 17:14:10.5334 UTC kernel.cc:944] Save model in resources\n",
            "[INFO 23-11-05 17:14:10.5375 UTC abstract_model.cc:881] Model self evaluation:\n",
            "Number of predictions (with weights): 1\n",
            "Task: REGRESSION\n",
            "Loss (SQUARED_ERROR): 9.5365\n",
            "\n",
            "RMSE: 3.08812\n",
            "Default RMSE: : 0\n",
            "\n",
            "[INFO 23-11-05 17:14:10.5500 UTC kernel.cc:1233] Loading model from path /tmp/tmplcgwh87_/model/ with prefix f76f0a1b20c74e3a\n",
            "[INFO 23-11-05 17:14:10.5674 UTC decision_forest.cc:660] Model loaded with 136 root(s), 15598 node(s), and 49 input feature(s).\n",
            "[INFO 23-11-05 17:14:10.5674 UTC abstract_model.cc:1343] Engine \"GradientBoostedTreesOptPred\" built\n",
            "[INFO 23-11-05 17:14:10.5674 UTC kernel.cc:1061] Use fast generic engine\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model trained in 0:25:11.353038\n",
            "Compiling model...\n",
            "Model compiled.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-5b3a6742376b>\u001b[0m in \u001b[0;36m<cell line: 41>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     40\u001b[0m }\n\u001b[1;32m     41\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN_fold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'gbtm'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-5-5b3a6742376b>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model_dict, modelname)\u001b[0m\n\u001b[1;32m     18\u001b[0m          )\n\u001b[1;32m     19\u001b[0m         \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mjoblib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf'./models/{modelname}_{i}.model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjoblib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{model_path}/{modelname}_{i}.model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/numpy_pickle.py\u001b[0m in \u001b[0;36mdump\u001b[0;34m(value, filename, compress, protocol, cache_size)\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0mNumpyPickler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mis_filename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 552\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    553\u001b[0m             \u001b[0mNumpyPickler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './models/gbtm_0.model'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def mae(ypred, ytrue):\n",
        "  return np.mean(np.abs((ypred.flatten() - ytrue)))\n",
        "for m in models:\n",
        "  pred = m.predict(X[index%N_fold==0])\n",
        "  print(mae(pred, Y[index%N_fold==0]))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-04T06:45:40.031176Z",
          "iopub.status.idle": "2023-11-04T06:45:40.031704Z",
          "shell.execute_reply.started": "2023-11-04T06:45:40.031434Z",
          "shell.execute_reply": "2023-11-04T06:45:40.031470Z"
        },
        "trusted": true,
        "id": "KzXWsqroreL8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tfdf.model_plotter.plot_model_in_colab(model=models[0], tree_idx=0, max_depth=8)"
      ],
      "metadata": {
        "trusted": true,
        "id": "_58r2KDGreL9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from google.colab import files\n",
        "for i in range(N_fold):\n",
        "    files.download(f\"./models/gbtm_{i}.model\")"
      ],
      "metadata": {
        "id": "ZEQW5qCLM-nu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "import optiver2023\n",
        "env = optiver2023.make_env()\n",
        "iter_test = env.iter_test()\n",
        "'''"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-04T06:45:40.035427Z",
          "iopub.status.idle": "2023-11-04T06:45:40.035755Z",
          "shell.execute_reply.started": "2023-11-04T06:45:40.035594Z",
          "shell.execute_reply": "2023-11-04T06:45:40.035609Z"
        },
        "trusted": true,
        "id": "U40-7m79reL9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "counter = 0\n",
        "for (test, revealed_targets, sample_prediction) in iter_test:\n",
        "    if counter == 0:\n",
        "        print(test.head(3))\n",
        "        print(revealed_targets.head(3))\n",
        "        print(sample_prediction.head(3))\n",
        "    sample_prediction['target'] = model.predict(test)\n",
        "    env.predict(sample_prediction)\n",
        "    counter += 1\n",
        "'''"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-04T06:45:40.036790Z",
          "iopub.status.idle": "2023-11-04T06:45:40.037136Z",
          "shell.execute_reply.started": "2023-11-04T06:45:40.036950Z",
          "shell.execute_reply": "2023-11-04T06:45:40.036965Z"
        },
        "trusted": true,
        "id": "hRvm6nMSreL-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}