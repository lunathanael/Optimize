{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# lib import \nimport numpy as np\nfrom numpy import inf\nimport pandas as pd\nimport tensorflow as tf\nimport tensorflow_decision_forests as tfdf\n\nTRAINING = True","metadata":{"papermill":{"duration":13038.093127,"end_time":"2023-10-29T23:49:47.421754","exception":false,"start_time":"2023-10-29T20:12:29.328627","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-11-05T03:05:49.628923Z","iopub.execute_input":"2023-11-05T03:05:49.629574Z","iopub.status.idle":"2023-11-05T03:05:49.635674Z","shell.execute_reply.started":"2023-11-05T03:05:49.629532Z","shell.execute_reply":"2023-11-05T03:05:49.634217Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"def generate_features(df):\n    features = ['seconds_in_bucket', 'imbalance_buy_sell_flag',\n               'imbalance_size', 'matched_size', 'bid_size', 'ask_size',\n                'reference_price','far_price', 'near_price', 'ask_price', 'bid_price', 'wap',\n                'imb_s1', 'imb_s2'\n               ]\n    \n    df['imb_s1'] = df.eval('(bid_size-ask_size)/(bid_size+ask_size)')\n    df['imb_s2'] = df.eval('(imbalance_size-matched_size)/(matched_size+imbalance_size)')\n    \n    prices = ['reference_price','far_price', 'near_price', 'ask_price', 'bid_price', 'wap']\n    \n    for i,a in enumerate(prices):\n        for j,b in enumerate(prices):\n            if i>j:\n                df[f'{a}_{b}_imb'] = df.eval(f'({a}-{b})/({a}+{b})')\n                features.append(f'{a}_{b}_imb')    \n                    \n    for i,a in enumerate(prices):\n        for j,b in enumerate(prices):\n            for k,c in enumerate(prices):\n                if i>j and j>k:\n                    max_ = df[[a,b,c]].max(axis=1)\n                    min_ = df[[a,b,c]].min(axis=1)\n                    mid_ = df[[a,b,c]].sum(axis=1)-min_-max_\n\n                    df[f'{a}_{b}_{c}_imb2'] = (max_-mid_)/(mid_-min_)\n                    features.append(f'{a}_{b}_{c}_imb2')\n    \n    return df[features]","metadata":{"execution":{"iopub.status.busy":"2023-11-05T03:05:49.638447Z","iopub.execute_input":"2023-11-05T03:05:49.639433Z","iopub.status.idle":"2023-11-05T03:05:49.650745Z","shell.execute_reply.started":"2023-11-05T03:05:49.639170Z","shell.execute_reply":"2023-11-05T03:05:49.649544Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"if TRAINING:\n    # load dataset \n    df_train = pd.read_csv('/kaggle/input/optiver-trading-at-the-close/train.csv')\n    df_features = generate_features(df_train)\n    \n    # data is defaulty normalized\n    X = np.float32(df_features.values)\n    Y = np.float32(df_train['target'].values)\n\n    X = X[np.isfinite(Y)]\n    Y = Y[np.isfinite(Y)]\n\n    index = np.arange(len(X)) #array for indexing\n\n    max_value = np.finfo(X.dtype).max #max float value allowed by numpy, perhaps lower? to prevent NAN during fit\n    min_value = np.finfo(X.dtype).min\n#     X[X==inf] = max_value\n#     X[~np.isfinite(X)] = min_value\n    X[X==inf] = 3.40282e+14\n    X[~np.isfinite(X)] = -3.40282e+14\n    \n    del df_train\n    del df_features","metadata":{"execution":{"iopub.status.busy":"2023-11-05T03:05:49.652533Z","iopub.execute_input":"2023-11-05T03:05:49.653137Z","iopub.status.idle":"2023-11-05T03:07:00.023346Z","shell.execute_reply.started":"2023-11-05T03:05:49.653101Z","shell.execute_reply":"2023-11-05T03:07:00.021939Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"import joblib \nimport os \nmodels = []\n\n# test to train ratio\nN_fold = 5\n\nos.system('mkdir models')\n\nmodel_path ='/kaggle/input/testing_data_set'\n\ndef train(model_dict, modelname='gbtm'):\n    if TRAINING:\n        model = model_dict[modelname]\n        model.fit(X[index%N_fold!=0], Y[index%N_fold!=0],\n          validation_data=(X[index%N_fold==0], Y[index%N_fold==0]),\n          verbose = 2\n         )\n        models.append(model)\n        joblib.dump(model, './models/{modelname}_{i}.model')\n    else:\n        models.append(joblib.load(f'{model_path}/{modelname}_{i}.model'))\n\n\nmodel_dict = {\n    'gbtm': tfdf.keras.GradientBoostedTreesModel(task = tfdf.keras.Task.REGRESSION,\n                                             split_axis='AXIS_ALIGNED', \n                                             categorical_algorithm='CART',\n                                             growing_strategy='LOCAL',\n                                             max_depth = 8,\n                                             sampling_method='RANDOM',\n                                             subsample=0.9,\n                                             shrinkage=0.1,\n                                             min_examples=10,\n                                             num_candidate_attributes_ratio=0.59\n                                             early_stopping='LOSS_INCREASE',\n                                             early_stopping_initial_iteration=100,\n                                             random_seed = 69\n                                            ),\n}\nfor i in range(N_fold):\n    train(model_dict, 'gbtm')","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2023-11-05T03:07:00.025550Z","iopub.execute_input":"2023-11-05T03:07:00.025938Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Use /tmp/tmpqrzozrmz as temporary training directory\n","output_type":"stream"},{"name":"stderr","text":"[WARNING 23-11-05 03:07:00.0636 UTC gradient_boosted_trees.cc:1818] \"goss_alpha\" set but \"sampling_method\" not equal to \"GOSS\".\n[WARNING 23-11-05 03:07:00.0636 UTC gradient_boosted_trees.cc:1829] \"goss_beta\" set but \"sampling_method\" not equal to \"GOSS\".\n[WARNING 23-11-05 03:07:00.0636 UTC gradient_boosted_trees.cc:1843] \"selective_gradient_boosting_ratio\" set but \"sampling_method\" not equal to \"SELGB\".\n","output_type":"stream"},{"name":"stdout","text":"Reading training dataset...\nTraining tensor examples:\nFeatures: Tensor(\"data:0\", shape=(None, 49), dtype=float32)\nLabel: Tensor(\"data_1:0\", shape=(None,), dtype=float32)\nWeights: None\nNormalized tensor features:\n {'data:0.0': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice:0' shape=(None,) dtype=float32>), 'data:0.1': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_1:0' shape=(None,) dtype=float32>), 'data:0.2': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_2:0' shape=(None,) dtype=float32>), 'data:0.3': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_3:0' shape=(None,) dtype=float32>), 'data:0.4': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_4:0' shape=(None,) dtype=float32>), 'data:0.5': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_5:0' shape=(None,) dtype=float32>), 'data:0.6': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_6:0' shape=(None,) dtype=float32>), 'data:0.7': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_7:0' shape=(None,) dtype=float32>), 'data:0.8': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_8:0' shape=(None,) dtype=float32>), 'data:0.9': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_9:0' shape=(None,) dtype=float32>), 'data:0.10': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_10:0' shape=(None,) dtype=float32>), 'data:0.11': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_11:0' shape=(None,) dtype=float32>), 'data:0.12': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_12:0' shape=(None,) dtype=float32>), 'data:0.13': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_13:0' shape=(None,) dtype=float32>), 'data:0.14': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_14:0' shape=(None,) dtype=float32>), 'data:0.15': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_15:0' shape=(None,) dtype=float32>), 'data:0.16': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_16:0' shape=(None,) dtype=float32>), 'data:0.17': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_17:0' shape=(None,) dtype=float32>), 'data:0.18': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_18:0' shape=(None,) dtype=float32>), 'data:0.19': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_19:0' shape=(None,) dtype=float32>), 'data:0.20': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_20:0' shape=(None,) dtype=float32>), 'data:0.21': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_21:0' shape=(None,) dtype=float32>), 'data:0.22': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_22:0' shape=(None,) dtype=float32>), 'data:0.23': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_23:0' shape=(None,) dtype=float32>), 'data:0.24': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_24:0' shape=(None,) dtype=float32>), 'data:0.25': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_25:0' shape=(None,) dtype=float32>), 'data:0.26': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_26:0' shape=(None,) dtype=float32>), 'data:0.27': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_27:0' shape=(None,) dtype=float32>), 'data:0.28': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_28:0' shape=(None,) dtype=float32>), 'data:0.29': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_29:0' shape=(None,) dtype=float32>), 'data:0.30': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_30:0' shape=(None,) dtype=float32>), 'data:0.31': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_31:0' shape=(None,) dtype=float32>), 'data:0.32': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_32:0' shape=(None,) dtype=float32>), 'data:0.33': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_33:0' shape=(None,) dtype=float32>), 'data:0.34': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_34:0' shape=(None,) dtype=float32>), 'data:0.35': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_35:0' shape=(None,) dtype=float32>), 'data:0.36': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_36:0' shape=(None,) dtype=float32>), 'data:0.37': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_37:0' shape=(None,) dtype=float32>), 'data:0.38': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_38:0' shape=(None,) dtype=float32>), 'data:0.39': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_39:0' shape=(None,) dtype=float32>), 'data:0.40': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_40:0' shape=(None,) dtype=float32>), 'data:0.41': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_41:0' shape=(None,) dtype=float32>), 'data:0.42': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_42:0' shape=(None,) dtype=float32>), 'data:0.43': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_43:0' shape=(None,) dtype=float32>), 'data:0.44': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_44:0' shape=(None,) dtype=float32>), 'data:0.45': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_45:0' shape=(None,) dtype=float32>), 'data:0.46': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_46:0' shape=(None,) dtype=float32>), 'data:0.47': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_47:0' shape=(None,) dtype=float32>), 'data:0.48': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_48:0' shape=(None,) dtype=float32>)}\nTraining dataset read in 0:00:43.390576. Found 4190313 examples.\nReading validation dataset...\nValidation tensor examples:\nFeatures: Tensor(\"data:0\", shape=(None, 49), dtype=float32)\nLabel: Tensor(\"data_1:0\", shape=(None,), dtype=float32)\nWeights: None\nNormalized tensor features:\n {'data:0.0': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice:0' shape=(None,) dtype=float32>), 'data:0.1': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_1:0' shape=(None,) dtype=float32>), 'data:0.2': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_2:0' shape=(None,) dtype=float32>), 'data:0.3': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_3:0' shape=(None,) dtype=float32>), 'data:0.4': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_4:0' shape=(None,) dtype=float32>), 'data:0.5': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_5:0' shape=(None,) dtype=float32>), 'data:0.6': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_6:0' shape=(None,) dtype=float32>), 'data:0.7': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_7:0' shape=(None,) dtype=float32>), 'data:0.8': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_8:0' shape=(None,) dtype=float32>), 'data:0.9': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_9:0' shape=(None,) dtype=float32>), 'data:0.10': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_10:0' shape=(None,) dtype=float32>), 'data:0.11': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_11:0' shape=(None,) dtype=float32>), 'data:0.12': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_12:0' shape=(None,) dtype=float32>), 'data:0.13': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_13:0' shape=(None,) dtype=float32>), 'data:0.14': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_14:0' shape=(None,) dtype=float32>), 'data:0.15': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_15:0' shape=(None,) dtype=float32>), 'data:0.16': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_16:0' shape=(None,) dtype=float32>), 'data:0.17': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_17:0' shape=(None,) dtype=float32>), 'data:0.18': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_18:0' shape=(None,) dtype=float32>), 'data:0.19': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_19:0' shape=(None,) dtype=float32>), 'data:0.20': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_20:0' shape=(None,) dtype=float32>), 'data:0.21': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_21:0' shape=(None,) dtype=float32>), 'data:0.22': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_22:0' shape=(None,) dtype=float32>), 'data:0.23': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_23:0' shape=(None,) dtype=float32>), 'data:0.24': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_24:0' shape=(None,) dtype=float32>), 'data:0.25': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_25:0' shape=(None,) dtype=float32>), 'data:0.26': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_26:0' shape=(None,) dtype=float32>), 'data:0.27': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_27:0' shape=(None,) dtype=float32>), 'data:0.28': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_28:0' shape=(None,) dtype=float32>), 'data:0.29': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_29:0' shape=(None,) dtype=float32>), 'data:0.30': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_30:0' shape=(None,) dtype=float32>), 'data:0.31': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_31:0' shape=(None,) dtype=float32>), 'data:0.32': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_32:0' shape=(None,) dtype=float32>), 'data:0.33': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_33:0' shape=(None,) dtype=float32>), 'data:0.34': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_34:0' shape=(None,) dtype=float32>), 'data:0.35': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_35:0' shape=(None,) dtype=float32>), 'data:0.36': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_36:0' shape=(None,) dtype=float32>), 'data:0.37': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_37:0' shape=(None,) dtype=float32>), 'data:0.38': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_38:0' shape=(None,) dtype=float32>), 'data:0.39': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_39:0' shape=(None,) dtype=float32>), 'data:0.40': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_40:0' shape=(None,) dtype=float32>), 'data:0.41': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_41:0' shape=(None,) dtype=float32>), 'data:0.42': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_42:0' shape=(None,) dtype=float32>), 'data:0.43': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_43:0' shape=(None,) dtype=float32>), 'data:0.44': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_44:0' shape=(None,) dtype=float32>), 'data:0.45': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_45:0' shape=(None,) dtype=float32>), 'data:0.46': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_46:0' shape=(None,) dtype=float32>), 'data:0.47': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_47:0' shape=(None,) dtype=float32>), 'data:0.48': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'strided_slice_48:0' shape=(None,) dtype=float32>)}\nNum validation examples: tf.Tensor(1047579, shape=(), dtype=int32)\nValidation dataset read in 0:00:13.716413. Found 1047579 examples.\nTraining model...\nStandard output detected as not visible to the user e.g. running in a notebook. Creating a training log redirection. If training gets stuck, try calling tfdf.keras.set_training_logs_redirection(False).\n","output_type":"stream"},{"name":"stderr","text":"[INFO 23-11-05 03:07:57.7320 UTC kernel.cc:773] Start Yggdrasil model training\n[INFO 23-11-05 03:07:57.7321 UTC kernel.cc:774] Collect training examples\n[INFO 23-11-05 03:07:57.7321 UTC kernel.cc:787] Dataspec guide:\ncolumn_guides {\n  column_name_pattern: \"^__LABEL$\"\n  type: NUMERICAL\n}\ndefault_column_guide {\n  categorial {\n    max_vocab_count: 2000\n  }\n  discretized_numerical {\n    maximum_num_bins: 255\n  }\n}\nignore_columns_without_guides: false\ndetect_numerical_as_discretized_numerical: false\n\n[INFO 23-11-05 03:07:57.7360 UTC kernel.cc:393] Number of batches: 130948\n[INFO 23-11-05 03:07:57.7360 UTC kernel.cc:394] Number of examples: 4190313\n[INFO 23-11-05 03:07:59.5003 UTC kernel.cc:794] Training dataset:\nNumber of records: 4190313\nNumber of columns: 50\n\nNumber of columns by type:\n\tNUMERICAL: 50 (100%)\n\nColumns:\n\nNUMERICAL: 50 (100%)\n\t0: \"__LABEL\" NUMERICAL mean:-0.0497912 min:-302.23 max:446.07 sd:9.38648\n\t1: \"data:0.0\" NUMERICAL mean:270.009 min:0 max:540 sd:158.745\n\t2: \"data:0.1\" NUMERICAL mean:-0.0135405 min:-1 max:1 sd:0.885101\n\t3: \"data:0.10\" NUMERICAL mean:-1.03133e+10 min:-3.40282e+14 max:1.07749 sd:1.87332e+12\n\t4: \"data:0.11\" NUMERICAL mean:-1.03133e+10 min:-3.40282e+14 max:1.07767 sd:1.87332e+12\n\t5: \"data:0.12\" NUMERICAL mean:-0.0137018 min:-0.999936 max:0.99994 sd:0.577446\n\t6: \"data:0.13\" NUMERICAL mean:-1.03133e+10 min:-3.40282e+14 max:0.983989 sd:1.87332e+12\n\t7: \"data:0.14\" NUMERICAL mean:-1.87996e+14 min:-3.40282e+14 max:0.995456 sd:1.69201e+14\n\t8: \"data:0.15\" NUMERICAL mean:-1.85613e+14 min:-3.40282e+14 max:0.131062 sd:1.69436e+14\n\t9: \"data:0.16\" NUMERICAL mean:-1.87996e+14 min:-3.40282e+14 max:0.999841 sd:1.69201e+14\n\t10: \"data:0.17\" NUMERICAL mean:-1.03133e+10 min:-3.40282e+14 max:0.0080918 sd:1.87332e+12\n\t11: \"data:0.18\" NUMERICAL mean:-1.87996e+14 min:-3.40282e+14 max:0.999845 sd:1.69201e+14\n\t12: \"data:0.19\" NUMERICAL mean:-1.85613e+14 min:-3.40282e+14 max:0.0540922 sd:1.69436e+14\n\t13: \"data:0.2\" NUMERICAL mean:-1.03076e+10 min:-3.40282e+14 max:2.98203e+09 sd:1.87332e+12\n\t14: \"data:0.20\" NUMERICAL mean:-1.03133e+10 min:-3.40282e+14 max:0.00473338 sd:1.87332e+12\n\t15: \"data:0.21\" NUMERICAL mean:-1.87996e+14 min:-3.40282e+14 max:0.999845 sd:1.69201e+14\n\t16: \"data:0.22\" NUMERICAL mean:-1.85613e+14 min:-3.40282e+14 max:0.0527488 sd:1.69436e+14\n\t17: \"data:0.23\" NUMERICAL mean:-1.03133e+10 min:-3.40282e+14 max:-1.49473e-06 sd:1.87332e+12\n\t18: \"data:0.24\" NUMERICAL mean:-1.03133e+10 min:-3.40282e+14 max:0.00672999 sd:1.87332e+12\n\t19: \"data:0.25\" NUMERICAL mean:-1.87996e+14 min:-3.40282e+14 max:0.999845 sd:1.69201e+14\n\t20: \"data:0.26\" NUMERICAL mean:-1.85613e+14 min:-3.40282e+14 max:0.0536176 sd:1.69436e+14\n\t21: \"data:0.27\" NUMERICAL mean:-1.03133e+10 min:-3.40282e+14 max:0 sd:1.87332e+12\n\t22: \"data:0.28\" NUMERICAL mean:-1.03133e+10 min:-3.40282e+14 max:0.0072404 sd:1.87332e+12\n\t23: \"data:0.29\" NUMERICAL mean:-1.46381e+13 min:-8.87497e+14 max:9.94665e+14 sd:8.47447e+13\n\t24: \"data:0.3\" NUMERICAL mean:-1.02683e+10 min:-3.40282e+14 max:7.71368e+09 sd:1.87332e+12\n\t25: \"data:0.30\" NUMERICAL mean:1.33744e+13 min:-4.62391e+16 max:2.26981e+17 sd:1.85864e+14\n\t26: \"data:0.31\" NUMERICAL mean:1.29783e+13 min:-8.97739e+14 max:8.99135e+14 sd:9.48561e+13\n\t27: \"data:0.32\" NUMERICAL mean:7.55216e+12 min:-8.87497e+14 max:9.57826e+14 sd:8.22656e+13\n\t28: \"data:0.33\" NUMERICAL mean:-4.45802e+12 min:-1.65395e+15 max:1.75739e+15 sd:4.36364e+13\n\t29: \"data:0.34\" NUMERICAL mean:-4.85338e+12 min:-8.99711e+14 max:8.96451e+14 sd:4.67298e+13\n\t30: \"data:0.35\" NUMERICAL mean:-2.64016e+12 min:-8.87497e+14 max:8.84534e+14 sd:5.23772e+13\n\t31: \"data:0.36\" NUMERICAL mean:2.89429e+13 min:-3.40282e+14 max:3.40282e+14 sd:9.49851e+13\n\t32: \"data:0.37\" NUMERICAL mean:4.40011e+12 min:-3.40282e+14 max:3.40282e+14 sd:3.85471e+13\n\t33: \"data:0.38\" NUMERICAL mean:5.13463e+12 min:-3.40282e+14 max:3.40282e+14 sd:4.15856e+13\n\t34: \"data:0.39\" NUMERICAL mean:7.06444e+12 min:-9.19698e+14 max:8.94694e+14 sd:4.89945e+13\n\t35: \"data:0.4\" NUMERICAL mean:51939.3 min:0.56 max:3.02878e+07 sd:111994\n\t36: \"data:0.40\" NUMERICAL mean:7.70641e+12 min:-4.51351e+14 max:4.46978e+14 sd:5.10678e+13\n\t37: \"data:0.41\" NUMERICAL mean:9.54366e+12 min:-8.80571e+14 max:8.882e+14 sd:5.78952e+13\n\t38: \"data:0.42\" NUMERICAL mean:1.96457e+11 min:-3.40282e+14 max:3.40282e+14 sd:1.19755e+13\n\t39: \"data:0.43\" NUMERICAL mean:5.73415e+10 min:-9.19698e+14 max:7.79717e+14 sd:6.2375e+12\n\t40: \"data:0.44\" NUMERICAL mean:5.93044e+10 min:-4.51351e+14 max:4.46037e+14 sd:6.12004e+12\n\t41: \"data:0.45\" NUMERICAL mean:2.90352e+13 min:-3.40282e+14 max:3.40282e+14 sd:9.5476e+13\n\t42: \"data:0.46\" NUMERICAL mean:4.38634e+12 min:-3.40282e+14 max:2.13807e+15 sd:3.8618e+13\n\t43: \"data:0.47\" NUMERICAL mean:5.12706e+12 min:-3.40282e+14 max:4.42262e+14 sd:4.16569e+13\n\t44: \"data:0.48\" NUMERICAL mean:2.04734e+11 min:-3.40282e+14 max:3.40282e+14 sd:8.75462e+12\n\t45: \"data:0.5\" NUMERICAL mean:53579.7 min:0.59 max:5.4405e+07 sd:129658\n\t46: \"data:0.6\" NUMERICAL mean:-1.03133e+10 min:-3.40282e+14 max:1.07749 sd:1.87332e+12\n\t47: \"data:0.7\" NUMERICAL mean:-1.87996e+14 min:-3.40282e+14 max:437.953 sd:1.69201e+14\n\t48: \"data:0.8\" NUMERICAL mean:-1.85613e+14 min:-3.40282e+14 max:1.30973 sd:1.69436e+14\n\t49: \"data:0.9\" NUMERICAL mean:-1.03133e+10 min:-3.40282e+14 max:1.07784 sd:1.87332e+12\n\nTerminology:\n\tnas: Number of non-available (i.e. missing) values.\n\tood: Out of dictionary.\n\tmanually-defined: Attribute which type is manually defined by the user i.e. the type was not automatically inferred.\n\ttokenized: The attribute value is obtained through tokenization.\n\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n\tvocab-size: Number of unique values.\n\n[INFO 23-11-05 03:07:59.5020 UTC kernel.cc:799] Collect validation dataset\n[INFO 23-11-05 03:07:59.5023 UTC kernel.cc:393] Number of batches: 32737\n[INFO 23-11-05 03:07:59.5023 UTC kernel.cc:394] Number of examples: 1047579\n[INFO 23-11-05 03:07:59.9456 UTC kernel.cc:805] Validation dataset:\nNumber of records: 1047579\nNumber of columns: 50\n\nNumber of columns by type:\n\tNUMERICAL: 50 (100%)\n\nColumns:\n\nNUMERICAL: 50 (100%)\n\t0: \"__LABEL\" NUMERICAL mean:-0.0386413 min:-385.29 max:357.44 sd:9.71382\n\t1: \"data:0.0\" NUMERICAL mean:269.967 min:0 max:540 sd:158.746\n\t2: \"data:0.1\" NUMERICAL mean:-0.00531893 min:-1 max:1 sd:0.886286\n\t3: \"data:0.10\" NUMERICAL mean:-1.62414e+09 min:-3.40282e+14 max:1.03284 sd:7.43412e+11\n\t4: \"data:0.11\" NUMERICAL mean:-1.62414e+09 min:-3.40282e+14 max:1.03426 sd:7.43412e+11\n\t5: \"data:0.12\" NUMERICAL mean:-0.0176723 min:-0.999896 max:0.999946 sd:0.587761\n\t6: \"data:0.13\" NUMERICAL mean:-1.62414e+09 min:-3.40282e+14 max:0.973598 sd:7.43412e+11\n\t7: \"data:0.14\" NUMERICAL mean:-1.88147e+14 min:-3.40282e+14 max:0.993494 sd:1.69185e+14\n\t8: \"data:0.15\" NUMERICAL mean:-1.85609e+14 min:-3.40282e+14 max:0.0479453 sd:1.69436e+14\n\t9: \"data:0.16\" NUMERICAL mean:-1.88147e+14 min:-3.40282e+14 max:0.999841 sd:1.69185e+14\n\t10: \"data:0.17\" NUMERICAL mean:-1.62414e+09 min:-3.40282e+14 max:0.00723934 sd:7.43412e+11\n\t11: \"data:0.18\" NUMERICAL mean:-1.88147e+14 min:-3.40282e+14 max:0.999845 sd:1.69185e+14\n\t12: \"data:0.19\" NUMERICAL mean:-1.85609e+14 min:-3.40282e+14 max:0.11032 sd:1.69436e+14\n\t13: \"data:0.2\" NUMERICAL mean:-1.6184e+09 min:-3.40282e+14 max:1.19269e+09 sd:7.43412e+11\n\t14: \"data:0.20\" NUMERICAL mean:-1.62414e+09 min:-3.40282e+14 max:0.00313479 sd:7.43412e+11\n\t15: \"data:0.21\" NUMERICAL mean:-1.88147e+14 min:-3.40282e+14 max:0.999845 sd:1.69185e+14\n\t16: \"data:0.22\" NUMERICAL mean:-1.85609e+14 min:-3.40282e+14 max:0.107143 sd:1.69436e+14\n\t17: \"data:0.23\" NUMERICAL mean:-1.62414e+09 min:-3.40282e+14 max:-2.00612e-06 sd:7.43412e+11\n\t18: \"data:0.24\" NUMERICAL mean:-1.62414e+09 min:-3.40282e+14 max:0.00537524 sd:7.43412e+11\n\t19: \"data:0.25\" NUMERICAL mean:-1.88147e+14 min:-3.40282e+14 max:0.999845 sd:1.69185e+14\n\t20: \"data:0.26\" NUMERICAL mean:-1.85609e+14 min:-3.40282e+14 max:0.109449 sd:1.69436e+14\n\t21: \"data:0.27\" NUMERICAL mean:-1.62414e+09 min:-3.40282e+14 max:0 sd:7.43412e+11\n\t22: \"data:0.28\" NUMERICAL mean:-1.62414e+09 min:-3.40282e+14 max:0.00645844 sd:7.43412e+11\n\t23: \"data:0.29\" NUMERICAL mean:-1.45718e+13 min:-1.00319e+15 max:8.80102e+14 sd:8.42881e+13\n\t24: \"data:0.3\" NUMERICAL mean:-1.57851e+09 min:-3.40282e+14 max:7.70462e+09 sd:7.43412e+11\n\t25: \"data:0.30\" NUMERICAL mean:1.35134e+13 min:-2.20187e+16 max:5.40527e+16 sd:1.25592e+14\n\t26: \"data:0.31\" NUMERICAL mean:1.28515e+13 min:-8.97946e+14 max:8.97937e+14 sd:9.32411e+13\n\t27: \"data:0.32\" NUMERICAL mean:8.03527e+12 min:-1.00319e+15 max:8.0927e+14 sd:8.16776e+13\n\t28: \"data:0.33\" NUMERICAL mean:-4.25817e+12 min:-9.04017e+14 max:1.13434e+15 sd:4.25992e+13\n\t29: \"data:0.34\" NUMERICAL mean:-4.59469e+12 min:-5.7202e+14 max:6.23956e+14 sd:4.57441e+13\n\t30: \"data:0.35\" NUMERICAL mean:-2.48502e+12 min:-8.86011e+14 max:8.80102e+14 sd:5.13811e+13\n\t31: \"data:0.36\" NUMERICAL mean:2.6616e+13 min:-3.40282e+14 max:3.40282e+14 sd:9.14103e+13\n\t32: \"data:0.37\" NUMERICAL mean:4.16601e+12 min:-3.40282e+14 max:3.40282e+14 sd:3.74256e+13\n\t33: \"data:0.38\" NUMERICAL mean:4.84808e+12 min:-3.40282e+14 max:3.40282e+14 sd:4.03619e+13\n\t34: \"data:0.39\" NUMERICAL mean:7.16024e+12 min:-4.5195e+14 max:4.49491e+14 sd:4.92836e+13\n\t35: \"data:0.4\" NUMERICAL mean:51315 min:12.71 max:2.70148e+07 sd:109105\n\t36: \"data:0.40\" NUMERICAL mean:7.76621e+12 min:-3.64305e+14 max:3.40282e+14 sd:5.12361e+13\n\t37: \"data:0.41\" NUMERICAL mean:9.54943e+12 min:-8.86263e+14 max:6.50824e+14 sd:5.79386e+13\n\t38: \"data:0.42\" NUMERICAL mean:2.21212e+11 min:-3.40282e+14 max:3.40282e+14 sd:1.18136e+13\n\t39: \"data:0.43\" NUMERICAL mean:6.87276e+10 min:-3.40282e+14 max:4.0395e+14 sd:5.83795e+12\n\t40: \"data:0.44\" NUMERICAL mean:6.72354e+10 min:-3.40282e+14 max:4.46068e+14 sd:5.75821e+12\n\t41: \"data:0.45\" NUMERICAL mean:2.6914e+13 min:-3.40282e+14 max:3.40282e+14 sd:9.22604e+13\n\t42: \"data:0.46\" NUMERICAL mean:4.19685e+12 min:-3.40282e+14 max:3.40282e+14 sd:3.77319e+13\n\t43: \"data:0.47\" NUMERICAL mean:4.93679e+12 min:-3.40282e+14 max:3.40282e+14 sd:4.08506e+13\n\t44: \"data:0.48\" NUMERICAL mean:1.97741e+11 min:-3.40282e+14 max:3.40282e+14 sd:8.26946e+12\n\t45: \"data:0.5\" NUMERICAL mean:53564.3 min:3.48 max:3.98234e+07 sd:128144\n\t46: \"data:0.6\" NUMERICAL mean:-1.62414e+09 min:-3.40282e+14 max:1.03854 sd:7.43412e+11\n\t47: \"data:0.7\" NUMERICAL mean:-1.88147e+14 min:-3.40282e+14 max:309.024 sd:1.69185e+14\n\t48: \"data:0.8\" NUMERICAL mean:-1.85609e+14 min:-3.40282e+14 max:1.12513 sd:1.69436e+14\n\t49: \"data:0.9\" NUMERICAL mean:-1.62414e+09 min:-3.40282e+14 max:1.03854 sd:7.43412e+11\n\nTerminology:\n\tnas: Number of non-available (i.e. missing) values.\n\tood: Out of dictionary.\n\tmanually-defined: Attribute which type is manually defined by the user i.e. the type was not automatically inferred.\n\ttokenized: The attribute value is obtained through tokenization.\n\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n\tvocab-size: Number of unique values.\n\n[INFO 23-11-05 03:07:59.9457 UTC kernel.cc:810] Configure learner\n[WARNING 23-11-05 03:07:59.9460 UTC gradient_boosted_trees.cc:1818] \"goss_alpha\" set but \"sampling_method\" not equal to \"GOSS\".\n[WARNING 23-11-05 03:07:59.9460 UTC gradient_boosted_trees.cc:1829] \"goss_beta\" set but \"sampling_method\" not equal to \"GOSS\".\n[WARNING 23-11-05 03:07:59.9460 UTC gradient_boosted_trees.cc:1843] \"selective_gradient_boosting_ratio\" set but \"sampling_method\" not equal to \"SELGB\".\n[INFO 23-11-05 03:07:59.9460 UTC kernel.cc:824] Training config:\nlearner: \"GRADIENT_BOOSTED_TREES\"\nfeatures: \"^data:0\\\\.0$\"\nfeatures: \"^data:0\\\\.1$\"\nfeatures: \"^data:0\\\\.10$\"\nfeatures: \"^data:0\\\\.11$\"\nfeatures: \"^data:0\\\\.12$\"\nfeatures: \"^data:0\\\\.13$\"\nfeatures: \"^data:0\\\\.14$\"\nfeatures: \"^data:0\\\\.15$\"\nfeatures: \"^data:0\\\\.16$\"\nfeatures: \"^data:0\\\\.17$\"\nfeatures: \"^data:0\\\\.18$\"\nfeatures: \"^data:0\\\\.19$\"\nfeatures: \"^data:0\\\\.2$\"\nfeatures: \"^data:0\\\\.20$\"\nfeatures: \"^data:0\\\\.21$\"\nfeatures: \"^data:0\\\\.22$\"\nfeatures: \"^data:0\\\\.23$\"\nfeatures: \"^data:0\\\\.24$\"\nfeatures: \"^data:0\\\\.25$\"\nfeatures: \"^data:0\\\\.26$\"\nfeatures: \"^data:0\\\\.27$\"\nfeatures: \"^data:0\\\\.28$\"\nfeatures: \"^data:0\\\\.29$\"\nfeatures: \"^data:0\\\\.3$\"\nfeatures: \"^data:0\\\\.30$\"\nfeatures: \"^data:0\\\\.31$\"\nfeatures: \"^data:0\\\\.32$\"\nfeatures: \"^data:0\\\\.33$\"\nfeatures: \"^data:0\\\\.34$\"\nfeatures: \"^data:0\\\\.35$\"\nfeatures: \"^data:0\\\\.36$\"\nfeatures: \"^data:0\\\\.37$\"\nfeatures: \"^data:0\\\\.38$\"\nfeatures: \"^data:0\\\\.39$\"\nfeatures: \"^data:0\\\\.4$\"\nfeatures: \"^data:0\\\\.40$\"\nfeatures: \"^data:0\\\\.41$\"\nfeatures: \"^data:0\\\\.42$\"\nfeatures: \"^data:0\\\\.43$\"\nfeatures: \"^data:0\\\\.44$\"\nfeatures: \"^data:0\\\\.45$\"\nfeatures: \"^data:0\\\\.46$\"\nfeatures: \"^data:0\\\\.47$\"\nfeatures: \"^data:0\\\\.48$\"\nfeatures: \"^data:0\\\\.5$\"\nfeatures: \"^data:0\\\\.6$\"\nfeatures: \"^data:0\\\\.7$\"\nfeatures: \"^data:0\\\\.8$\"\nfeatures: \"^data:0\\\\.9$\"\nlabel: \"^__LABEL$\"\ntask: REGRESSION\nrandom_seed: 69\nmetadata {\n  framework: \"TF Keras\"\n}\npure_serving_model: false\n[yggdrasil_decision_forests.model.gradient_boosted_trees.proto.gradient_boosted_trees_config] {\n  num_trees: 300\n  decision_tree {\n    max_depth: 4\n    min_examples: 7\n    in_split_min_examples_check: true\n    keep_non_leaf_label_distribution: true\n    missing_value_policy: GLOBAL_IMPUTATION\n    allow_na_conditions: false\n    categorical_set_greedy_forward {\n      sampling: 0.1\n      max_num_items: -1\n      min_item_frequency: 1\n    }\n    growing_strategy_local {\n    }\n    categorical {\n      cart {\n      }\n    }\n    num_candidate_attributes_ratio: 0.5\n    sparse_oblique_split {\n      projection_density_factor: 2\n      binary_weight: false\n      normalization: STANDARD_DEVIATION\n    }\n    internal {\n      sorting_strategy: PRESORTED\n    }\n    uplift {\n      min_examples_in_treatment: 5\n      split_score: KULLBACK_LEIBLER\n    }\n  }\n  shrinkage: 0.05\n  loss: DEFAULT\n  validation_set_ratio: 0.1\n  validation_interval_in_trees: 1\n  early_stopping: VALIDATION_LOSS_INCREASE\n  early_stopping_num_trees_look_ahead: 30\n  l2_regularization: 0\n  lambda_loss: 1\n  mart {\n  }\n  adapt_subsample_for_maximum_training_duration: false\n  l1_regularization: 0\n  use_hessian_gain: false\n  l2_regularization_categorical: 1\n  stochastic_gradient_boosting {\n    ratio: 0.9\n  }\n  apply_link_function: true\n  compute_permutation_variable_importance: false\n  binary_focal_loss_options {\n    misprediction_exponent: 2\n    positive_sample_coefficient: 0.5\n  }\n  early_stopping_initial_iteration: 100\n}\n\n[INFO 23-11-05 03:07:59.9465 UTC kernel.cc:827] Deployment config:\ncache_path: \"/tmp/tmpqrzozrmz/working_cache\"\nnum_threads: 4\ntry_resume_training: true\n\n[INFO 23-11-05 03:07:59.9481 UTC kernel.cc:889] Train model\n[INFO 23-11-05 03:07:59.9487 UTC gradient_boosted_trees.cc:459] Default loss set to SQUARED_ERROR\n[INFO 23-11-05 03:07:59.9487 UTC gradient_boosted_trees.cc:1085] Training gradient boosted tree on 4190313 example(s) and 49 feature(s).\n[INFO 23-11-05 03:07:59.9489 UTC gradient_boosted_trees.cc:1128] 4190313 examples used for training and 1047579 examples used for validation\n[INFO 23-11-05 03:18:35.2737 UTC gradient_boosted_trees.cc:1542] \tnum-trees:1 train-loss:9.377206 train-rmse:9.377206 valid-loss:9.703630 valid-rmse:9.703630\n[INFO 23-11-05 03:29:02.7748 UTC gradient_boosted_trees.cc:1544] \tnum-trees:2 train-loss:9.368633 train-rmse:9.368633 valid-loss:9.694145 valid-rmse:9.694145\n[INFO 23-11-05 03:39:35.9678 UTC gradient_boosted_trees.cc:1544] \tnum-trees:3 train-loss:9.360325 train-rmse:9.360325 valid-loss:9.684995 valid-rmse:9.684995\n[INFO 23-11-05 03:39:35.9678 UTC gradient_boosted_trees.cc:1566] Create a snapshot of the model at iteration 2\n[INFO 23-11-05 03:50:12.4486 UTC gradient_boosted_trees.cc:1544] \tnum-trees:4 train-loss:9.352813 train-rmse:9.352813 valid-loss:9.676679 valid-rmse:9.676679\n[INFO 23-11-05 04:00:41.7517 UTC gradient_boosted_trees.cc:1544] \tnum-trees:5 train-loss:9.345903 train-rmse:9.345903 valid-loss:9.669293 valid-rmse:9.669293\n[INFO 23-11-05 04:11:06.4719 UTC gradient_boosted_trees.cc:1544] \tnum-trees:6 train-loss:9.339358 train-rmse:9.339358 valid-loss:9.662110 valid-rmse:9.662110\n[INFO 23-11-05 04:11:06.4720 UTC gradient_boosted_trees.cc:1566] Create a snapshot of the model at iteration 5\n[INFO 23-11-05 04:21:49.7355 UTC gradient_boosted_trees.cc:1544] \tnum-trees:7 train-loss:9.333450 train-rmse:9.333450 valid-loss:9.655457 valid-rmse:9.655457\n[INFO 23-11-05 04:32:22.8080 UTC gradient_boosted_trees.cc:1544] \tnum-trees:8 train-loss:9.327878 train-rmse:9.327878 valid-loss:9.649174 valid-rmse:9.649174\n[INFO 23-11-05 04:42:51.2253 UTC gradient_boosted_trees.cc:1544] \tnum-trees:9 train-loss:9.322793 train-rmse:9.322793 valid-loss:9.643458 valid-rmse:9.643458\n[INFO 23-11-05 04:42:51.2253 UTC gradient_boosted_trees.cc:1566] Create a snapshot of the model at iteration 8\n[INFO 23-11-05 04:53:24.0494 UTC gradient_boosted_trees.cc:1544] \tnum-trees:10 train-loss:9.318059 train-rmse:9.318059 valid-loss:9.638391 valid-rmse:9.638391\n[INFO 23-11-05 05:03:56.3093 UTC gradient_boosted_trees.cc:1544] \tnum-trees:11 train-loss:9.313662 train-rmse:9.313662 valid-loss:9.633668 valid-rmse:9.633668\n[INFO 23-11-05 05:14:23.0172 UTC gradient_boosted_trees.cc:1544] \tnum-trees:12 train-loss:9.309509 train-rmse:9.309509 valid-loss:9.628535 valid-rmse:9.628535\n[INFO 23-11-05 05:14:23.0172 UTC gradient_boosted_trees.cc:1566] Create a snapshot of the model at iteration 11\n[INFO 23-11-05 05:24:59.0280 UTC gradient_boosted_trees.cc:1544] \tnum-trees:13 train-loss:9.305910 train-rmse:9.305910 valid-loss:9.624618 valid-rmse:9.624618\n[INFO 23-11-05 05:35:29.9179 UTC gradient_boosted_trees.cc:1544] \tnum-trees:14 train-loss:9.302412 train-rmse:9.302412 valid-loss:9.620998 valid-rmse:9.620998\n[INFO 23-11-05 05:45:55.1540 UTC gradient_boosted_trees.cc:1544] \tnum-trees:15 train-loss:9.299284 train-rmse:9.299284 valid-loss:9.617712 valid-rmse:9.617712\n[INFO 23-11-05 05:45:55.1540 UTC gradient_boosted_trees.cc:1566] Create a snapshot of the model at iteration 14\n","output_type":"stream"}]},{"cell_type":"code","source":"tfdf.model_plotter.plot_model_in_colab(model=models[0], tree_idx=0, max_depth=4)","metadata":{"execution":{"iopub.status.busy":"2023-11-05T14:55:56.257842Z","iopub.execute_input":"2023-11-05T14:55:56.258294Z","iopub.status.idle":"2023-11-05T14:55:56.303880Z","shell.execute_reply.started":"2023-11-05T14:55:56.258257Z","shell.execute_reply":"2023-11-05T14:55:56.301958Z"},"trusted":true},"execution_count":1,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtfdf\u001b[49m\u001b[38;5;241m.\u001b[39mmodel_plotter\u001b[38;5;241m.\u001b[39mplot_model_in_colab(model\u001b[38;5;241m=\u001b[39mmodels[\u001b[38;5;241m0\u001b[39m], tree_idx\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, max_depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m)\n","\u001b[0;31mNameError\u001b[0m: name 'tfdf' is not defined"],"ename":"NameError","evalue":"name 'tfdf' is not defined","output_type":"error"}]},{"cell_type":"code","source":"'''\nimport optiver2023\nenv = optiver2023.make_env()\niter_test = env.iter_test()\n'''","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\ncounter = 0\nfor (test, revealed_targets, sample_prediction) in iter_test:\n    if counter == 0:\n        print(test.head(3))\n        print(revealed_targets.head(3))\n        print(sample_prediction.head(3))\n    sample_prediction['target'] = model.predict(test)\n    env.predict(sample_prediction)\n    counter += 1\n'''","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}